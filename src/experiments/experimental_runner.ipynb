{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dc134e",
   "metadata": {},
   "source": [
    "# Put this directly in src\n",
    "- there will be the new path src/saved_experiments which you have to delete afterwards\n",
    "- you need to put a data.csv in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ec5f538-674c-4c9e-94a2-5016b4713924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Will read dataset from data.csv\n",
      "Filled 13959 NA values in column IMU-BACK-accX\n",
      "Filled 13959 NA values in column IMU-BACK-accY\n",
      "Filled 13959 NA values in column IMU-BACK-accZ\n",
      "Filled 13959 NA values in column IMU-BACK-Quaternion1\n",
      "Filled 13959 NA values in column IMU-BACK-Quaternion2\n",
      "Filled 13959 NA values in column IMU-BACK-Quaternion3\n",
      "Filled 13959 NA values in column IMU-BACK-Quaternion4\n",
      "Filled 13959 NA values in column IMU-RLA-accX\n",
      "Filled 13959 NA values in column IMU-RLA-accY\n",
      "Filled 13959 NA values in column IMU-RLA-accZ\n",
      "Filled 13959 NA values in column IMU-RLA-Quaternion1\n",
      "Filled 13959 NA values in column IMU-RLA-Quaternion2\n",
      "Filled 13959 NA values in column IMU-RLA-Quaternion3\n",
      "Filled 13959 NA values in column IMU-RLA-Quaternion4\n",
      "Filled 13959 NA values in column IMU-LLA-accX\n",
      "Filled 13959 NA values in column IMU-LLA-accY\n",
      "Filled 13959 NA values in column IMU-LLA-accZ\n",
      "Filled 13959 NA values in column IMU-LLA-Quaternion1\n",
      "Filled 13959 NA values in column IMU-LLA-Quaternion2\n",
      "Filled 13959 NA values in column IMU-LLA-Quaternion3\n",
      "Filled 13959 NA values in column IMU-LLA-Quaternion4\n",
      "Filled 3485 NA values in column IMU-L-SHOE-EuX\n",
      "Filled 3485 NA values in column IMU-L-SHOE-EuY\n",
      "Filled 3485 NA values in column IMU-L-SHOE-EuZ\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Nav_Ax\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Nav_Ay\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Nav_Az\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Body_Ax\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Body_Ay\n",
      "Filled 3485 NA values in column IMU-L-SHOE-Body_Az\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelBodyFrameX\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelBodyFrameY\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelBodyFrameZ\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelNavFrameX\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelNavFrameY\n",
      "Filled 3485 NA values in column IMU-L-SHOE-AngVelNavFrameZ\n",
      "Filled 3485 NA values in column IMU-R-SHOE-EuX\n",
      "Filled 3485 NA values in column IMU-R-SHOE-EuY\n",
      "Filled 3485 NA values in column IMU-R-SHOE-EuZ\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Nav_Ax\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Nav_Ay\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Nav_Az\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Body_Ax\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Body_Ay\n",
      "Filled 3485 NA values in column IMU-R-SHOE-Body_Az\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelBodyFrameX\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelBodyFrameY\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelBodyFrameZ\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelNavFrameX\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelNavFrameY\n",
      "Filled 3485 NA values in column IMU-R-SHOE-AngVelNavFrameZ\n",
      "convert to Recording objects...\n",
      "number of NaN before interpolation 397689\n",
      "number of NaN after interpolation 0\n",
      "\n",
      "===> WARNING: the window_size is big with the used windowize algorithm (Jens) you have much data loss!!! (each activity can only be a multiple of the half the window_size, with overlapping a half of a window is cutted)\n",
      "\n",
      "=> jens_windowize_monitoring (total recording time)\n",
      "\tbefore: 4h 20m\n",
      "\tafter: 4h 18m\n",
      "n_total_timesteps: 469663\n",
      "n_wasted_timesteps: 4543\n",
      "windowizing in progress ....\n",
      "windowizing done\n",
      "\n",
      "===> WARNING: the window_size is big with the used windowize algorithm (Jens) you have much data loss!!! (each activity can only be a multiple of the half the window_size, with overlapping a half of a window is cutted)\n",
      "\n",
      "=> jens_windowize_monitoring (total recording time)\n",
      "\tbefore: 1h 37m\n",
      "\tafter: 1h 35m\n",
      "n_total_timesteps: 174953\n",
      "n_wasted_timesteps: 2423\n",
      "windowizing in progress ....\n",
      "windowizing done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "keras exp\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from loader.load_dataset import load_dataset\n",
    "from loader.Preprocessor import Preprocessor\n",
    "import utils.settings as settings\n",
    "from utils.array_operations import split_list_by_percentage\n",
    "\n",
    "from utils.folder_operations import new_saved_experiment_folder\n",
    "from evaluation.conf_matrix import create_conf_matrix\n",
    "from evaluation.text_metrics import create_text_metrics\n",
    "from evaluation.metrics import accuracy, f1_score\n",
    "from utils.Windowizer import Windowizer\n",
    "from sklearn.model_selection import KFold\n",
    "from utils.Converter import Converter\n",
    "\n",
    "from models.JensModel import JensModel\n",
    "from models.MultilaneConv import MultilaneConv\n",
    "from models.BestPerformerConv import BestPerformerConv\n",
    "from models.OldLSTM import OldLSTM\n",
    "from models.MultilaneConvLSTM import MultilaneConvLSTM\n",
    "\n",
    "\n",
    "settings.init()\n",
    "\n",
    "# Lib -----------------------------------------------------------\n",
    "leave_recording_out_split = lambda test_percentage: lambda recordings: split_list_by_percentage(list_to_split=recordings, percentage_to_split=test_percentage)\n",
    "# leave_recording_out_split(test_percentage=0.3)(recordings)\n",
    "def leave_person_out_split_idx(recordings, test_person_idx):\n",
    "    subset_from_condition = lambda condition, recordings: [recording for recording in recordings if condition(recording)] \n",
    "    recordings_train = subset_from_condition(lambda recording: recording.subject != test_person_idx, recordings)\n",
    "    recordings_test = subset_from_condition(lambda recording: recording.subject == test_person_idx, recordings)\n",
    "    return recordings_train, recordings_test\n",
    "leave_person_out_split = lambda test_person_idx: lambda recordings: leave_person_out_split_idx(recordings=recordings, test_person_idx=test_person_idx)\n",
    "# leave_person_out_split(test_person_idx=2)(recordings) # 1-4, TODO: could be random\n",
    "\n",
    "\n",
    "# Config --------------------------------------------------------------------------------------------------------------\n",
    "window_size = 30*3\n",
    "n_classes = 6\n",
    "\n",
    "data_path = 'data.csv' # os.path.join(settings.opportunity_dataset_csv_path, 'data.csv')\n",
    "load_recordings = lambda: load_dataset(data_path, \n",
    "    label_column_name='ACTIVITY_IDX', \n",
    "    recording_idx_name='RECORDING_IDX', \n",
    "    column_names_to_ignore=['SUBJECT_IDX', 'MILLISECONDS']\n",
    ")\n",
    "\n",
    "preprocess = lambda recordings: Preprocessor().jens_preprocess_with_normalize(recordings)\n",
    "windowize = lambda recordings: Windowizer(window_size=window_size).jens_windowize(recordings)\n",
    "convert = lambda windows: Converter(n_classes=n_classes).sonar_convert(windows)\n",
    "flatten = lambda tuple_list: [item for sublist in tuple_list for item in sublist]\n",
    "test_train_split = lambda recordings: leave_recording_out_split(test_percentage=0.3)(recordings)\n",
    "\n",
    "\n",
    "# Load data\n",
    "recordings = load_recordings()\n",
    "\n",
    "random.seed(72727277235074) # 1678978086101\n",
    "random.shuffle(recordings)\n",
    "\n",
    "# Preprocessing\n",
    "recordings = preprocess(recordings)\n",
    "\n",
    "# Test Train Split\n",
    "recordings_train, recordings_test = test_train_split(recordings)\n",
    "\n",
    "# Windowize\n",
    "windows_train, windows_test = windowize(recordings_train), windowize(recordings_test)\n",
    "\n",
    "# Convert\n",
    "X_train, y_train, X_test, y_test = tuple(flatten(map(convert, [windows_train, windows_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dea9325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-95027cd68d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m'project'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'all_experiments_project'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m'entity'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'valentindoering'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     }\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;32m~/github/EvA/src/models/RainbowModel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/EvA/src/models/AlternativeDeepConvLSTM.py\u001b[0m in \u001b[0;36m_create_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2634\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mycondaenv/lib/python3.6/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 32)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.JensModel import JensModel\n",
    "from models.MultilaneConv import MultilaneConv\n",
    "from models.BestPerformerConv import BestPerformerConv\n",
    "from models.OldLSTM import OldLSTM\n",
    "from models.MultilaneConvLSTM import MultilaneConvLSTM\n",
    "from models.KirillAlexDeepConvLSTM import KirillAlexDeepConvLSTM\n",
    "from models.AlternativeDeepConvLSTM import AlternativeDeepConvLSTM\n",
    "\n",
    "experiment_name = \"deep-conv-lstm\"\n",
    "\n",
    "currentDT = datetime.now()\n",
    "currentDT_str = currentDT.strftime(\"%y-%m-%d_%H-%M-%S_%f\")\n",
    "experiment_name = experiment_name + \"-\" + currentDT_str\n",
    "\n",
    "# or JensModel\n",
    "model = AlternativeDeepConvLSTM(\n",
    "    window_size=window_size, \n",
    "    n_features=recordings[0].sensor_frame.shape[1], \n",
    "    n_outputs=n_classes, \n",
    "    n_epochs=5, \n",
    "    learning_rate=0.001, \n",
    "    batch_size=32, \n",
    "    wandb_config={\n",
    "        'project': 'all_experiments_project',\n",
    "        'entity': 'valentindoering',\n",
    "        'name': experiment_name\n",
    "    }\n",
    ")\n",
    "# learning_rate=0.001\n",
    "# wandb_project=experiment_name\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Create Folder, save model export and evaluations there\n",
    "experiment_folder_path = new_saved_experiment_folder(experiment_name) # create folder to store results\n",
    "\n",
    "# model.export(experiment_folder_path) # opt: export model to folder\n",
    "create_conf_matrix(experiment_folder_path, y_test_pred, y_test)\n",
    "create_text_metrics(experiment_folder_path, y_test_pred, y_test, [accuracy]) # TODO: at the moment only with one function working! data gets changed (passed by reference) - refactor metric functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
